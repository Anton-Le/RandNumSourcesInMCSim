{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18791d97",
   "metadata": {},
   "source": [
    "# Evaluation of $\\pi$ calculation using DSMC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499104d7",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaa8308",
   "metadata": {},
   "source": [
    "This notebook is used to evaluate a collection of experimental assays used to estimate $\\pi$ with PRNGs and the QRNG.\n",
    "\n",
    "The basis for the statistical tests introduced in this notebook are the PRNG and QRNG datasets consisting of multiple repetitions\n",
    "of the following set-up:\n",
    "\n",
    "- An experimental assay of\n",
    "        - A varying number of batches: 2, 8, 16, 64, 128, 256\n",
    "        - With a varying number of repetitions of the Pi estimation within each batch: 10, 20, 40, 80, 100, 150, 200\n",
    "        - And a varying number of sample points to estimate Pi for each repetition: 100 000, 1 000 000\n",
    "\n",
    "This notebook is used to process the raw data of _all_ experimental assays (**it is assumed that the same number of runs exists for PRNGs and the QRNG**), store the accumulated data and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100392f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ee425d",
   "metadata": {},
   "source": [
    "In this document we try to adhere to the following notation:\n",
    "- The true value of the constant is denoted $\\pi$.\n",
    "- An approximate value obtained by sampling the unit square is denoted $\\tilde{\\pi}_i = \\frac{\\text{points within unit circle}}{\\text{total points}}$, where $i$ is the index of the sample value.\n",
    "- An averaging operation is denoted by $\\langle \\cdot\\rangle_N$, where $N$ indicates the number of values being averaged over.\n",
    "- An expectation value and variance of a random variable $X$ are denoted as $\\mathbb{E}[X],Var[X]$ and their empirical equivalents are $\\mu(x) = \\langle X \\rangle_N, s_n^2(x)=\\frac{1}{n-1}\\sum_{i=1}^{N} (x_i - \\mu(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a9c1c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16306731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os, shutil, sys, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad78745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb07c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figsize=(6,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b01f4d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Raw data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149cf37f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c707c0e7",
   "metadata": {},
   "source": [
    "First we define the assay parameters along with the directories for QRNG and PRNG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150f93e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assayRootdirQRNG = \"/programs/extension/QDice_tests/PiTesting/RUN/asymptoticAssay_buffon_QRNG_errorfixed_NETDEVICE/run\"\n",
    "assayRootdirPRNG = \"/programs/extension/QDice_tests/PiTesting/RUN/asymptoticAssay_buffon_pPRNG_mrg5s/run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a262780-7fe1-4ee1-90f3-b3d57689b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assayDirNameTemplateQRNG=\"{assayId:d}/{precision:s}\"\n",
    "assayDirNameTemplatePRNG=\"{assayId:d}/{precision:s}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c943fd-2e8b-45ed-b83e-6f9dc5757454",
   "metadata": {},
   "source": [
    "**Note**: For data generated using Snakemake workflows the parameters below are taken from the workflow's `configuration.yaml` and could, in principle, be parsed automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4a754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#parallel run parameters\n",
    "Nbatches= [4, 8, 16, 32, 64, 128, 256]\n",
    "Nrep= [10, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200]\n",
    "Nsamples=[int(i) for i in [10000, 100000] ]\n",
    "\n",
    "NumAssays = 10\n",
    "\n",
    "precision=\"double\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b379065",
   "metadata": {},
   "source": [
    "Change into the directory of the QRNG experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc792176-e31a-4be0-8770-e84ad8f4837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assayDirQRNG = assayRootdirQRNG+'/'+assayDirNameTemplateQRNG.format(assayId=1, precision=precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c0c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(assayDirQRNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd28a5",
   "metadata": {},
   "source": [
    "A sample name of the results, as codified in the `assay.sh` scripts is: `results_assay2__batchSize_8_Nrep_10_samples_1000000.txt`\n",
    "\n",
    "Using the naming scheme we define a template for the result filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d12ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ResultFilenameTemplate=\"results_assay_{assayId:d}__batchSize_{batchSize:d}_Nrep_{Nrep:d}_samples_{Nsamples:d}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb36a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat results_assay_1__batchSize_16_Nrep_10_samples_100000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3d646a",
   "metadata": {},
   "source": [
    "The above shows the contents of a given case. The result file contains two lines:\n",
    "- The first line contains #repetitions, `<pi>`, `Var[pi]`, [list of #repetitions approximations]\n",
    "- The second line contains #repetitions, `|pi-<pi>|`, `Var[|pi-<pi>|]`, [list of #repetitions abs. errors]\n",
    "\n",
    "Using this information we may create a parser for the results. The function takes a file name and outputs a dictionary containing:    \n",
    "- No. of repetitions $N$ - integer\n",
    "- $\\langle \\tilde{\\pi} \\rangle_N$ - scalar\n",
    "- $Var[\\tilde{\\pi}]$ - scalar\n",
    "- $\\langle |\\tilde{\\pi} - \\pi| \\rangle_N$ - scalar\n",
    "- $Var[ | \\tilde{\\pi} - \\pi |]$ - scalar\n",
    "- $\\tilde{\\pi}_i$ - numpy array of samples\n",
    "- $|\\tilde{\\pi}_i - \\pi |$ - numpy array of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01af5610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parseResults(filename:str):\n",
    "    data = np.genfromtxt(filename, delimiter=',')\n",
    "    data = data[:,:-1]\n",
    "    results = {}\n",
    "    results[\"Nrep\"] = int(data[0,0])\n",
    "    results['meanPi'] = data[0,1]\n",
    "    results['varPi'] = data[0,2]\n",
    "    results['meanAbsErr'] = data[1,1]\n",
    "    results['varAbsErr'] = data[1,2]\n",
    "    \n",
    "    results['piSamples'] = np.copy(data[0,3:])\n",
    "    results['absErrSamples'] = np.copy(data[1,3:])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b634f5e",
   "metadata": {},
   "source": [
    "This notebook is used to evaluate data obtained with code which includes the iteration over the batch into the C++ source. In this case the output is of size 2*`batchSize` and consists of pairs of lines structured as presented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb10d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseBatchedResults(filename:str, batchSize:int):\n",
    "    '''\n",
    "    The routine is used to obtain results from DSMC calculations of \n",
    "    pi that were run in batched mode of the C++ code.\n",
    "    In this case the output file contains ``batchSize`` pairs of results\n",
    "    as defined above.\n",
    "    '''\n",
    "    data = np.genfromtxt(filename, delimiter=',')\n",
    "    obtainedBatchSize = data.shape[0]//2\n",
    "    assert obtainedBatchSize == batchSize, \"Wrong batch size!\"\n",
    "    data = data[:,:-1]\n",
    "    Nrep = int(data[0,0])\n",
    "    means = np.zeros(batchSize)\n",
    "    var = np.zeros(batchSize)\n",
    "    errorMeans = np.zeros(batchSize)\n",
    "    errorVariances = np.zeros(batchSize)\n",
    "    samples = np.zeros((batchSize, Nrep)) \n",
    "    errorSamples = np.zeros((batchSize, Nrep)) \n",
    "    #copy data appropriately\n",
    "    means = np.copy(data[0::2, 1])\n",
    "    var = np.copy(data[0::2, 2])\n",
    "    errorMeans = np.copy( data[1::2, 1] )\n",
    "    errorVariances = np.copy( data[1::2, 2] )\n",
    "    samples = np.copy( data[0::2, 3:] )\n",
    "    errorSamples = np.copy( data[0::2, 3:] )\n",
    "    return (means, var, errorMeans, errorVariances, samples, errorSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a66d66",
   "metadata": {
    "tags": []
   },
   "source": [
    "### QRNG data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2b2929",
   "metadata": {},
   "source": [
    "Prior to collecting and storing the data we note the following:\n",
    "\n",
    "The varying number of batches prescribed in `Nbatches` is arbitrary and can be varied _a-posteriori_ since it influences only the calculation of the _mean of means_ and of the confidence interval.\n",
    "\n",
    "Hence grouping of the data is performed using only the number of repetitions `N` and number of samples `S`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89ead8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PointsPerRepAndSampleSize = np.sum( np.array(Nbatches) )\n",
    "print(PointsPerRepAndSampleSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ecd015",
   "metadata": {
    "tags": []
   },
   "source": [
    "This defines how many datapoints each configuration $(N,S)$ will yield.\n",
    "\n",
    "**This will likely change in the future to use either Pandas or Xarray for a more flexible data storage and ease of visualisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_batched1 = np.zeros( (NumAssays, len(Nrep), len(Nsamples), PointsPerRepAndSampleSize), dtype=float )\n",
    "variances_batched1 = np.zeros( (NumAssays, len(Nrep), len(Nsamples), PointsPerRepAndSampleSize), dtype=float )\n",
    "\n",
    "absErrorMeans_batched1 = np.zeros( (NumAssays, len(Nrep), len(Nsamples), PointsPerRepAndSampleSize), dtype=float )\n",
    "absErrorVariances_batched1 = np.zeros( (NumAssays, len(Nrep), len(Nsamples), PointsPerRepAndSampleSize), dtype=float )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02623db-69ba-4531-b0d2-9b8a1c04611d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#iterate over the assays\n",
    "for assayId in range(1, NumAssays+1):\n",
    "    assayDirQRNG = assayRootdirQRNG+'/'+assayDirNameTemplateQRNG.format(assayId=assayId, precision=precision)\n",
    "    os.chdir(assayDirQRNG)\n",
    "    \n",
    "    batchOffsetIdx = 0;\n",
    "    #iterate over the batch sizes\n",
    "    for batchSize in Nbatches:\n",
    "            #iterate over the number of repetitions\n",
    "            for nrep, repIdx in zip(Nrep, range(len(Nrep) ) ):\n",
    "                #terate over the number of samples\n",
    "                for nSamples, nSamplesIdx in zip(Nsamples, range(len(Nsamples)) ):\n",
    "                    filenameParameters= {'assayId':assayId,'batchSize':batchSize, 'Nrep':nrep, 'Nsamples':nSamples}\n",
    "                    filename = ResultFilenameTemplate.format(**filenameParameters)\n",
    "                    data = parseResults(filename)\n",
    "                    batchMeans, batchVar, batchErrorMeans, batchErrorVariances, samples, sampleErrors = parseBatchedResults(filename, batchSize)\n",
    "                    #distribute data to the arrays\n",
    "                    means_batched1[assayId-1, repIdx, nSamplesIdx, batchOffsetIdx:batchOffsetIdx + batchSize] = np.copy(batchMeans)\n",
    "                    variances_batched1[assayId-1, repIdx, nSamplesIdx, batchOffsetIdx:batchOffsetIdx + batchSize] = np.copy(batchVar)\n",
    "                    \n",
    "                    absErrorMeans_batched1[assayId-1, repIdx, nSamplesIdx, batchOffsetIdx:batchOffsetIdx + batchSize] = np.copy(batchErrorMeans)\n",
    "                    absErrorVariances_batched1[assayId-1, repIdx, nSamplesIdx, batchOffsetIdx:batchOffsetIdx + batchSize] = np.copy(batchErrorVariances)\n",
    "                    # end of the samples loop\n",
    "                #end of the Nrep loop\n",
    "            batchOffsetIdx += batchSize # increment the running index to store the data appropriately\n",
    "    #end of the batch loop\n",
    "    os.chdir(assayRootdirQRNG) #return to the common directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3acbb8-ec4b-405d-9988-0f5fbdc592de",
   "metadata": {},
   "source": [
    "Collection of the raw $\\tilde{\\pi}_i$ samples does not require a distinction between assays, numbers of repetitions or batches. Each $\\tilde{\\pi}_i$ is a sample in its own right and the distinction is only made by the number of sample points  on $[0,1]\\times[0,1]$ used to obtain the $\\tilde{\\pi}_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b48bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for raw samples - distinguishable only by the number of points on [0,1]^2 used to obtain the estimates\n",
    "\n",
    "rawSamples = []\n",
    "rawSampleErrors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e5f4c",
   "metadata": {},
   "source": [
    "Collect sample data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557766b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#iterate over the assays\n",
    "for nSamples, nSamplesIdx in zip(Nsamples, range(len(Nsamples)) ):\n",
    "    sampleData = []\n",
    "    sampleErrorData = []\n",
    "    for assayId in range(1, NumAssays+1):\n",
    "        assayDirQRNG = assayRootdirQRNG+'/'+assayDirNameTemplateQRNG.format(assayId=assayId, precision=precision)\n",
    "        os.chdir(assayDirQRNG)\n",
    "        #iterate over the number of batches\n",
    "        for batchSize in Nbatches:\n",
    "            #iterate over the number of repetitions\n",
    "            for nrep, repIdx in zip(Nrep, range(len(Nrep) ) ):\n",
    "                filenameParameters= {'assayId':assayId,'batchSize':batchSize, 'Nrep':nrep, 'Nsamples':nSamples}\n",
    "                filename = ResultFilenameTemplate.format(**filenameParameters)\n",
    "                rawData = pd.read_csv(filename, header=None)\n",
    "                sampleData.append(rawData.iloc[::2,3:-1].values.flatten())\n",
    "                sampleErrorData.append(rawData.iloc[1::2,3:-1].values.flatten())\n",
    "            #end of Nrep loop\n",
    "        #end of batch size loop\n",
    "    os.chdir(assayRootdirQRNG)\n",
    "    #end assay loop\n",
    "    rawSamples.append( sampleData )\n",
    "    rawSampleErrors.append( sampleErrorData)\n",
    "    #end of the data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c180bc-6a56-40d1-9832-db474c3658fe",
   "metadata": {},
   "source": [
    "Due to the use of multiple assays the samples have to be rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4cd99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexedSamples = {}.fromkeys(Nsamples)\n",
    "indexedAbsErrSamples = {}.fromkeys(Nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a8fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, idx in zip(indexedSamples, range(len(Nsamples))):\n",
    "    indexedSamples[key] = np.concatenate( rawSamples[idx] )\n",
    "    indexedAbsErrSamples[key] = np.concatenate( rawSampleErrors[idx] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesDF = pd.DataFrame(indexedSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "absErrSamplesDF = pd.DataFrame(indexedAbsErrSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf1eaf7-679e-4e87-9e1c-c94b9ad9ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert samplesDF.shape[0] == np.sum(Nrep) * np.sum(Nbatches) * NumAssays, \"Incorrect number of points collected!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c810d3f",
   "metadata": {},
   "source": [
    "Store to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesDF.to_csv(\"rawSamples_parallel_asymptotic_{precision:s}_QRNG.csv\".format(precision=precision))\n",
    "absErrSamplesDF.to_csv(\"rawAbsErrorSamples_parallel_asymptotic_{precision:s}_QRNG.csv\".format(precision=precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1f047",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simple visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbins = int( np.ceil(1 + np.log2( samplesDF.shape[0] )) )\n",
    "samplesDF.hist(bins=Nbins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc77239",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PRNG data collection and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b87ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(assayRootdirPRNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "prngmeans_batched1 = np.zeros( (NumAssays,len(Nrep), len(Nsamples), PointsPerRepAndSampleSize), dtype=float )\n",
    "prngvariances_batched1 = np.zeros( (NumAssays,len(Nrep), len(Nsamples), PointsPerRepAndSampleSize), dtype=float )\n",
    "\n",
    "prngabsErrorMeans_batched1 = np.zeros( (NumAssays,len(Nrep), len(Nsamples), PointsPerRepAndSampleSize), dtype=float )\n",
    "prngabsErrorVariances_batched1 = np.zeros( (NumAssays,len(Nrep), len(Nsamples), PointsPerRepAndSampleSize), dtype=float )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ea769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#iterate over the assays\n",
    "for assayId in range(1, NumAssays+1):\n",
    "    assayDirPRNG = assayRootdirPRNG+'/'+assayDirNameTemplatePRNG.format(assayId=assayId, precision=precision)\n",
    "    os.chdir(assayDirPRNG)\n",
    "    \n",
    "    batchOffsetIdx = 0;\n",
    "    #iterate over the batch sizes\n",
    "    for batchSize in Nbatches:\n",
    "            #iterate over the number of repetitions\n",
    "            for nrep, repIdx in zip(Nrep, range(len(Nrep) ) ):\n",
    "                #terate over the number of samples\n",
    "                for nSamples, nSamplesIdx in zip(Nsamples, range(len(Nsamples)) ):\n",
    "                    filenameParameters= {'assayId':assayId,'batchSize':batchSize, 'Nrep':nrep, 'Nsamples':nSamples}\n",
    "                    filename = ResultFilenameTemplate.format(**filenameParameters)\n",
    "                    data = parseResults(filename)\n",
    "                    batchMeans, batchVar, batchErrorMeans, batchErrorVariances, samples, sampleErrors = parseBatchedResults(filename, batchSize)\n",
    "                    #distribute data to the arrays\n",
    "                    prngmeans_batched1[assayId-1, repIdx, nSamplesIdx, batchOffsetIdx:batchOffsetIdx + batchSize] = np.copy(batchMeans)\n",
    "                    prngvariances_batched1[assayId-1, repIdx, nSamplesIdx, batchOffsetIdx:batchOffsetIdx + batchSize] = np.copy(batchVar)\n",
    "                    \n",
    "                    prngabsErrorMeans_batched1[assayId-1, repIdx, nSamplesIdx, batchOffsetIdx:batchOffsetIdx + batchSize] = np.copy(batchErrorMeans)\n",
    "                    prngabsErrorVariances_batched1[assayId-1, repIdx, nSamplesIdx, batchOffsetIdx:batchOffsetIdx + batchSize] = np.copy(batchErrorVariances)\n",
    "                    # end of the samples loop\n",
    "                #end of the Nrep loop\n",
    "            batchOffsetIdx += batchSize # increment the running index to store the data appropriately\n",
    "    #end of the batch loop\n",
    "    os.chdir(assayRootdirPRNG) #return to the common directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for raw samples - distinguishable only by the number of points on [0,1]^2 used to obtain the estimates\n",
    "rawSamples = []\n",
    "rawSampleErrors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca2c61",
   "metadata": {},
   "source": [
    "Collect sample data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e712053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over the assays\n",
    "for nSamples, nSamplesIdx in zip(Nsamples, range(len(Nsamples)) ):\n",
    "    sampleData = []\n",
    "    sampleErrorData = []\n",
    "    for assayId in range(1, NumAssays+1):\n",
    "        assayDirPRNG = assayRootdirPRNG+'/'+assayDirNameTemplatePRNG.format(assayId=assayId, precision=precision)\n",
    "        os.chdir(assayDirPRNG)\n",
    "        #iterate over the number of batches\n",
    "        for batchSize in Nbatches:\n",
    "            #iterate over the number of repetitions\n",
    "            for nrep, repIdx in zip(Nrep, range(len(Nrep) ) ):\n",
    "                filenameParameters= {'assayId':assayId,'batchSize':batchSize, 'Nrep':nrep, 'Nsamples':nSamples}\n",
    "                filename = ResultFilenameTemplate.format(**filenameParameters)\n",
    "                rawData = pd.read_csv(filename, header=None)\n",
    "                sampleData.append(rawData.iloc[::2,3:-1].values.flatten())\n",
    "                sampleErrorData.append(rawData.iloc[1::2,3:-1].values.flatten())\n",
    "            #end of Nrep loop\n",
    "        #end of batch size loop\n",
    "    os.chdir(assayRootdirPRNG)\n",
    "    #end assay loop\n",
    "    rawSamples.append( sampleData )\n",
    "    rawSampleErrors.append( sampleErrorData)\n",
    "    #end of the data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d317fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexedSamples = {}.fromkeys(Nsamples)\n",
    "indexedAbsErrSamples = {}.fromkeys(Nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffd22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, idx in zip(indexedSamples, range(len(Nsamples))):\n",
    "    indexedSamples[key] = np.concatenate( rawSamples[idx] )\n",
    "    indexedAbsErrSamples[key] = np.concatenate( rawSampleErrors[idx] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d33fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesDF_prng = pd.DataFrame(indexedSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faeb1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "absErrSamplesDF_prng = pd.DataFrame(indexedAbsErrSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba68628",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesDF_prng.to_csv(\"rawSamples_parallel_asymptotic_{precision:s}_pPRNG.csv\".format(precision=precision))\n",
    "absErrSamplesDF_prng.to_csv(\"rawAbsErrorSamples_parallel_asymptotic_{precision:s}_pPRNG.csv\".format(precision=precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a9eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(assayRootdirPRNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6beb0d-6f7f-4091-b70a-4a061156f514",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eefe1a-b791-4f5b-907b-6be0f92ee31a",
   "metadata": {},
   "source": [
    "The preceding parts of the notebook are used to accumulate raw data into CSV files. These should then be processed by the `DSMCPIEvaluation_MulticaseMerged.ipynb` notebook.\n",
    "\n",
    "The sections following below serve to provide a first glance at the distributions of the freshly processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f729c5a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Combine the raw samples of QRNG and PRNG into a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24afd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "st1p = samplesDF_prng.T\n",
    "\n",
    "st1q = samplesDF.T"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a8473eb-0de4-4723-a02f-1165f312301c",
   "metadata": {},
   "source": [
    "st1p = st1p.assign(method = [ \"prng\", \"prng\"])\n",
    "st1q = st1q.assign(method = [ \"qrng\", \"qrng\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d61c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedSamples_prng = samplesDF_prng\n",
    "combinedSamples_qrng = samplesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b47ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedSamples_prng.hist(density=True, bins=Nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ec8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedSamples_qrng.hist(density=True, bins=Nbins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110420b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simple visualisation of PRNG and QRNG data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41445cd4-d767-448e-ad22-f187366815c5",
   "metadata": {},
   "source": [
    "Define confidence parameter $\\alpha$ and the confidence interval for the mean-of-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14bfc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha=0.05\n",
    "CIrange=1-alpha/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f9dbd-74ef-4c6a-bada-523b1b7c2495",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_batched1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4050044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prngcase1_means = prngmeans_batched1[:,-1,-1,:].flatten()\n",
    "prngcase1_variances = prngvariances_batched1[:,-1,-1,:].flatten()\n",
    "\n",
    "\n",
    "qrngcase1_means = means_batched1[:,-1,-1,:].flatten()\n",
    "qrngcase1_variances = variances_batched1[:,-1,-1,:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ee244-9697-4e69-a625-936100ed0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prngcase1_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319eec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prngbatchMeans = np.zeros( len(Nbatches) )\n",
    "prngbatchVariances = np.zeros_like(prngbatchMeans)\n",
    "prngweightingFactors = np.zeros_like(prngbatchMeans)\n",
    "\n",
    "\n",
    "qrngbatchMeans = np.zeros( len(Nbatches) )\n",
    "qrngbatchVariances = np.zeros_like(qrngbatchMeans)\n",
    "qrngweightingFactors = np.zeros_like(qrngbatchMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686f2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(Nbatches)):\n",
    "    #PRNG\n",
    "    prngbatchMeans[i] = np.average( prngcase1_means[:Nbatches[i]] )\n",
    "    prngbatchVariances[i] = np.var( prngcase1_means[:Nbatches[i]], ddof=1 )\n",
    "    prngweightingFactors[i] = stats.t.ppf(CIrange, Nbatches[i] - 1)\n",
    "    #QRNG\n",
    "    qrngbatchMeans[i] = np.average( qrngcase1_means[:Nbatches[i]] )\n",
    "    qrngbatchVariances[i] = np.var( qrngcase1_means[:Nbatches[i]], ddof=1 )\n",
    "    qrngweightingFactors[i] = stats.t.ppf(CIrange, Nbatches[i] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4324c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prngerrorbarLimits = np.zeros_like(prngweightingFactors)\n",
    "qrngerrorbarLimits = np.zeros_like(qrngweightingFactors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69609594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(Nbatches)):\n",
    "    prngerrorbarLimits[i] = prngweightingFactors[i] * np.sqrt(prngbatchVariances[i] / Nbatches[i] )\n",
    "    qrngerrorbarLimits[i] = qrngweightingFactors[i] * np.sqrt(qrngbatchVariances[i] / Nbatches[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d3cfb",
   "metadata": {},
   "source": [
    "Plot a combined errorbar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f2439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.errorbar( Nbatches, qrngbatchMeans, yerr=qrngerrorbarLimits, marker='o', capsize=5, capthick=4, lw=0,  label=\"QRNG\" )\n",
    "ax.errorbar( Nbatches, prngbatchMeans, yerr=prngerrorbarLimits, marker='x',capsize=5,capthick=4, lw=0, label=\"PRNG - MT19937\" )\n",
    "ax.axhline(np.pi, color='r', label=\"$\\pi$\")\n",
    "ax.legend(loc='best')\n",
    "\n",
    "ax.set_xlabel(\"Batch size\", fontsize=14)\n",
    "ax.set_xscale('log', base=2)\n",
    "ax.set_ylabel(\"$\\\\langle \\\\tilde{\\pi}\\\\rangle$\", fontsize=14)\n",
    "\n",
    "ax.set_title(\"DSMC $\\pi$ approx. - $N_{samples}=10^6$\")\n",
    "\n",
    "ax.grid(which='both')\n",
    "#fig.savefig(\"DSMC_QRNG_PRNG_CI_vs_ BatchSize_99percentCI.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b8e5bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualisation of multiple confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrngcase1_means.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29458fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NsamplesMultibatchVis = qrngcase1_means.shape[0]//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04666d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prngbatchMeans = np.zeros( 4 )\n",
    "prngbatchVariances = np.zeros_like(prngbatchMeans)\n",
    "prngweightingFactors = np.zeros_like(prngbatchMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5cc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrngbatchMeans = np.zeros( 4 )\n",
    "qrngbatchVariances = np.zeros_like(qrngbatchMeans)\n",
    "qrngweightingFactors = np.zeros_like(qrngbatchMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5fd603",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    prngbatchMeans[i] = np.average( prngcase1_means[i*NsamplesMultibatchVis:(i+1)*NsamplesMultibatchVis] )\n",
    "    prngbatchVariances[i] = np.var( prngcase1_means[i*NsamplesMultibatchVis:(i+1)*NsamplesMultibatchVis], ddof=1 )\n",
    "    prngweightingFactors[i] = stats.t.ppf(CIrange, NsamplesMultibatchVis - 1)\n",
    "    qrngbatchMeans[i] = np.average( qrngcase1_means[i*NsamplesMultibatchVis:(i+1)*NsamplesMultibatchVis] )\n",
    "    qrngbatchVariances[i] = np.var( qrngcase1_means[i*NsamplesMultibatchVis:(i+1)*NsamplesMultibatchVis], ddof=1 )\n",
    "    qrngweightingFactors[i] = stats.t.ppf(CIrange, NsamplesMultibatchVis - 1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prngerrorbarLimits = np.zeros_like(prngweightingFactors)\n",
    "qrngerrorbarLimits = np.zeros_like(qrngweightingFactors)\n",
    "\n",
    "for i in range(4):\n",
    "    prngerrorbarLimits[i] = prngweightingFactors[i] * np.sqrt(prngbatchVariances[i] / NsamplesMultibatchVis )\n",
    "    qrngerrorbarLimits[i] = qrngweightingFactors[i] * np.sqrt(qrngbatchVariances[i] / NsamplesMultibatchVis )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fdfacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIlocations= np.arange(1,4+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc79cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.errorbar( CIlocations, qrngbatchMeans, yerr=qrngerrorbarLimits, marker='o', capsize=5, capthick=4, lw=0,  label=\"method 1\" )\n",
    "ax.errorbar( CIlocations+0.25, prngbatchMeans, yerr=prngerrorbarLimits, marker='o', capsize=5, capthick=4, lw=0,  label=\"method 2\" )\n",
    "ax.axhline(np.pi, color='r', label=\"True value\")\n",
    "ax.legend(loc='best', fontsize=14)\n",
    "\n",
    "ax.set_xlabel(\"Batch number\", fontsize=14)\n",
    "ax.set_ylabel(\"$\\\\langle \\\\tilde{\\pi}\\\\rangle$\", fontsize=14)\n",
    "ax.set_ylim([np.pi-1e-4, np.pi+1e-4])\n",
    "ax.set_yticks([np.pi-1e-4, np.pi-1e-4/4, np.pi,np.pi+1e-4/4, np.pi+1e-4])\n",
    "ax.set_xticks(CIlocations)\n",
    "ax.set_yticklabels([\"$\\\\pi-10^{-4}$\", \"$\\\\pi-1/4\\cdot10^{-4}$\", \"$\\\\pi$\",\"$\\\\pi+1/4\\cdot10^{-4}$\", \"$\\\\pi+10^{-4}$\"], fontsize=14)\n",
    "ax.set_title(\"99% Confidence intervals of 104 measuerements\", fontsize=14)\n",
    "\n",
    "ax.grid(which='major')\n",
    "#fig.savefig(\"DSMC_CIvariation.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26c0a6",
   "metadata": {},
   "source": [
    "#### Visualising confidence intervals with violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36473f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "case1_means_split = np.split(qrngcase1_means, 4)\n",
    "prngcase1_means_split = np.split(prngcase1_means, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36bad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.violinplot(case1_means_split, positions=CIlocations,  showmedians=True)\n",
    "ax.violinplot(prngcase1_means_split, positions=(CIlocations+0.25),  showmedians=True)\n",
    "ax.errorbar( CIlocations, qrngbatchMeans, yerr=qrngerrorbarLimits, marker='o', capsize=5, capthick=4, lw=0,  label=\"QRNG\" )\n",
    "ax.errorbar( CIlocations+0.25, prngbatchMeans, yerr=prngerrorbarLimits, marker='o', capsize=5, capthick=4, lw=0,  label=\"PRNG\" )\n",
    "ax.axhline(np.pi, color='r', label=\"True value\")\n",
    "ax.legend(loc='best', fontsize=14)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Batch number\", fontsize=14)\n",
    "ax.set_ylabel(\"$\\\\langle \\\\tilde{\\pi}\\\\rangle$\", fontsize=14)\n",
    "#ax.set_ylim([np.pi-1e-4, np.pi+1e-4])\n",
    "#ax.set_yticks([np.pi-1e-4, np.pi-1e-4/4, np.pi,np.pi+1e-4/4, np.pi+1e-4])\n",
    "ax.set_xticks(CIlocations)\n",
    "#ax.set_yticklabels([\"$\\\\pi-10^{-4}$\", \"$\\\\pi-1/4\\cdot10^{-4}$\", \"$\\\\pi$\",\"$\\\\pi+1/4\\cdot10^{-4}$\", \"$\\\\pi+10^{-4}$\"], fontsize=14)\n",
    "ax.set_title(\"Distribution and 99% CI of 104 measuerements\", fontsize=14)\n",
    "\n",
    "\n",
    "ax.grid(which='major')\n",
    "#fig.savefig(\"DSMC_CIvariationWithDist.png\", dpi=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
